{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "yQaldy8SH6Dl",
        "PBTbrJXOngz2",
        "rFu4xreNphqO",
        "OVtJsKN_phqQ",
        "tgIPom80phqQ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/visapthakur/-team-netflix-movies-and-tv-shows-clustering-/blob/main/INDIVIDUAL_NETFLIX_MOVIES_AND_TV_SHOWS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - NETFLIX_MOVIES_AND_TV_SHOWS_CLUSTERING\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "##### **Contribution**    - INDIVIDUAL\n",
        "##### **Team Member 1** - VISHAL TOMER"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the summary here within 500-600 words.\n",
        "\n",
        "\n",
        "This dataset consist of  tv shows and movies available on netflix as of 2019 .the dataset is collected from   flixable which is a third party search engine .\n",
        "in 2018 they  released an  interesting report  which shows that the no of tv shows on netflix has really tripled since 2010. The streaming services number of movies had dedcreased  by more than 2000 titles since 2010, while its number of tv shows  has nearly tripled .it will be interesting to explore   what all other insights  can be obtained from the same dataset ,integrating this dataset with other external datasets such as IMDB rating, rotten tomatoes can also provide many interesting findings .The goal of this project is to classify/group the Netflix shows into certain clusters such that the shows within a cluster are similar to each other and the shows in different clusters are dissimilar to each other.We will be able to understand the shows that are similar to and different from one another by creating clusters, which may be leveraged to offer the consumers personalized show suggestions depending on their preferences.Netflix is the world's largest online streaming service provider, with over 220 million subscribers as of 2022-Q2. It is crucial that they effectively cluster the shows that are hosted on their platform in order to enhance the user experience, thereby preventing subscriber churn."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write Problem Statement Here.**\n",
        "\n",
        "# This dataset consists of tv shows and movies available on Netflix as of 2019. The dataset is collected from Flixable which is a third-party Netflix search engine.\n",
        "\n",
        "#In 2018, they released an interesting report which shows that the number of TV shows on Netflix has nearly tripled since 2010. The streaming serviceâ€™s number of movies has decreased by more than 2,000 titles since 2010, while its number of TV shows has nearly tripled. It will be interesting to explore what all other insights can be obtained from the same dataset.\n",
        "\n",
        "#Integrating this dataset with other external datasets such as IMDB ratings, rotten tomatoes can also provide many interesting findings.\n",
        "\n",
        "# In this project, you are required to do\n",
        "\n",
        "\n",
        "\n",
        "#Exploratory Data Analysis\n",
        "\n",
        "#Understanding what type content is available in different countries\n",
        "\n",
        "#Is Netflix has increasingly focusing on TV rather than movies in recent years.\n",
        "\n",
        "# Clustering similar content by matching text-based features"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Attribute Information**\n",
        "\n",
        "\n",
        "#show_id : Unique ID for every Movie / Tv Show\n",
        "\n",
        "#type : Identifier - A Movie or TV Show\n",
        "\n",
        "#title : Title of the Movie / Tv Show\n",
        "\n",
        "#director : Director of the Movie\n",
        "\n",
        "#cast : Actors involved in the movie / show\n",
        "\n",
        "#country : Country where the movie / show was produced\n",
        "\n",
        "#date_added : Date it was added on Netflix\n",
        "\n",
        "#release_year : Actual Releaseyear of the movie / show\n",
        "\n",
        "#rating : TV Rating of the movie / show\n",
        "\n",
        "#duration : Total Duration - in minutes or number of seasons\n",
        "\n",
        "#listed_in : Genere\n",
        "\n",
        "#description: The Summary description"
      ],
      "metadata": {
        "id": "UfrYo8aukKnT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required. \n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits. \n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule. \n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime as dt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import re, string, unicodedata\n",
        "import nltk\n",
        "#import inflect\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "string.punctuation\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import scipy.cluster.hierarchy as shc\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set()"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tqqBFD9WljmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "initial_df =  pd.read_csv('/content/NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = initial_df.copy()"
      ],
      "metadata": {
        "id": "k8mY4UUqmW2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "# head of the data\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "print(\"Duplicate entry in df:\",len(df[df.duplicated()])) "
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "plt.figure(figsize = (10,8), facecolor = 'y')\n",
        "ax = plt.gca()\n",
        "sns.heatmap(df.isnull(), cmap = 'Blues_r', ax =ax,  linecolor = 'r')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping date_added and rating rows where values are missing\n",
        "df = df.dropna(axis =0, subset = ['date_added', 'rating'] )\n",
        "df['date_added'].isnull().sum()"
      ],
      "metadata": {
        "id": "P5bxXWQbns4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "We don't have null or infinite values dataset but have some null values in netflix movies dataset and we have to deal with it in future"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe(include='all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "\n",
        "#show_id : Unique ID for every Movie / Tv Show\n",
        "\n",
        "#type : Identifier - A Movie or TV Show\n",
        "\n",
        "#title : Title of the Movie / Tv Show\n",
        "\n",
        "#director : Director of the Movie\n",
        "\n",
        "#cast : Actors involved in the movie / show\n",
        "\n",
        "#country : Country where the movie / show was produced\n",
        "\n",
        "#date_added : Date it was added on Netflix\n",
        "\n",
        "#release_year : Actual Releaseyear of the movie / show\n",
        "\n",
        "#rating : TV Rating of the movie / show\n",
        "\n",
        "#duration : Total Duration - in minutes or number of seasons\n",
        "\n",
        "#listed_in : Genere\n",
        "\n",
        "#description: The Summary description"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for i in df.columns.tolist():\n",
        "  print(\"No. of unique values in\",i,\"is\",df[i].nunique())"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Summing null values\n",
        "print('Missing Data Count')\n",
        "df.isna().sum()[df.isna().sum() > 0].sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Missing Data Percentage')\n",
        "print(round(df.isna().sum()[df.isna().sum() > 0].sort_values(ascending=False)/len(df)*100,2))"
      ],
      "metadata": {
        "id": "VFqSbcCToWpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The missing values in the 'director', 'cast', and 'country' columns can be replaced with the label 'Unknown'.\n",
        "df[['director']] = df[['director']].fillna('Unknown')\n",
        "df[['cast']]     = df[['cast']].fillna('Unknown')\n",
        "df[['country'] ] = df[['country']].fillna('Unknown')"
      ],
      "metadata": {
        "id": "ZHGO8c_ioeR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        "\n",
        "Merging datasets: We don't want to compromise with quality and quantity of our dataset in order to get the best accuracy in ML model implementation. So, we were wondering to use the best join for the good results and we got to know with our R&D that every join is giving the same shape of our merged dataset with 0 null values"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining a function to get the year addedfrom the date_added\n",
        "def func_1(x):\n",
        "  return x.split()[0]"
      ],
      "metadata": {
        "id": "Qyi5U2Wm9-GQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the head of the dataset\n",
        "df.head()"
      ],
      "metadata": {
        "id": "wyXYkN-x992w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining two sub-datasets based on type of the content\n",
        "shows_df = df[df['type'] == 'TV Show']\n",
        "movie_df  = df[df['type']== 'Movie']"
      ],
      "metadata": {
        "id": "WaXCsgpi99uh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a column n movie_df dataframe using func_1 funtion\n",
        "movie_df['duration'] = movie_df['duration'].apply(func_1)"
      ],
      "metadata": {
        "id": "pvoLMB6X-B26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "# plotting the type distribution\n",
        "sns.set_style('darkgrid')\n",
        "\n",
        "\n",
        "plt.figure(figsize = (8,6))\n",
        "df['type'].value_counts().plot.pie(autopct=\"%1.1f%%\", cmap = 'Paired', shadow=True, startangle=190,explode=(0.04,0.04));\n",
        "plt.title('Distribution of content Type')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a  TV shows dataset where imputed values are not taking into account\n",
        "tv_shows_df = df[df['type'] == 'TV Show']\n",
        "tv_shows_df = tv_shows_df[tv_shows_df['country'] != 'missing']\n",
        "\n",
        "# creating a  movies dataset where imputed values are not taking into account\n",
        "movies_df  = df[df['type']== 'Movie']\n",
        "movies_df = movies_df[movies_df['country'] != 'missing']\n",
        "\n",
        "\n",
        "# getting unique values shows dataframe\n",
        "country_df_shows = pd.DataFrame(tv_shows_df['country'].str.split(', ', expand= True).stack().reset_index(level =1, drop = True).value_counts()).reset_index()\n",
        "country_df_shows.rename(columns = {'index': 'country', 0:'shows counts'}, inplace =True)\n",
        "top_15_countries = country_df_shows.head(15)\n",
        "\n",
        "# getting unique values shows dataframe fir movies\n",
        "country_df_movies = pd.DataFrame(movies_df['country'].str.split(', ', expand= True).stack().reset_index(level =1, drop = True).value_counts()).reset_index()\n",
        "country_df_movies.rename(columns = {'index': 'country', 0:'movies counts'}, inplace =True)\n",
        "top_15_countries_movies = country_df_movies.head(15)\n",
        "new_df = pd.concat([top_15_countries, top_15_countries_movies] , axis =1)\n",
        "\n",
        "# final dataframe\n",
        "new_df\n"
      ],
      "metadata": {
        "id": "og5gi5l3_xvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# top 10 directors who have directed most move\n",
        "director_df  =  df[df['director'] != 'None']\n",
        "director_df = pd.DataFrame(director_df['director'].value_counts().head(10)).reset_index()\n",
        "director_df.rename(columns = {'index' : 'director', 'director' : 'counts'}, inplace= True)\n",
        "director_df\n"
      ],
      "metadata": {
        "id": "T9aBQoyx_xrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        "\n",
        "We choose the pie chart as it represents the tv show and movies of each part of the data to a whole where the arc size of each slice is directly proportional to the contribution of that part"
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "We see that movies 69.1% of and 30.9%  in type for count."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "Later we will see if their is any impact of Response on Netflix Movies."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Seasons"
      ],
      "metadata": {
        "id": "9uoLPSec_8C5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "plt.figure(figsize = (10,7))\n",
        "\n",
        "\n",
        "seasons_df = pd.DataFrame(shows_df['duration'].value_counts()).reset_index()\n",
        "seasons_df.rename(columns = {'index': 'seasons', 'duration': 'counts'}, inplace = True)\n",
        "sns.barplot(data =seasons_df, x= 'seasons', y= 'counts')\n",
        "plt.xticks(rotation = 60)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "seasons_df"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        "\n",
        "We choose the chart as it represents the count & seasons  of each part of the data to a whole where the arc size of each slice is directly proportional to the contribution of that part"
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "We see that season 1 has maximum count & season 16 has minimum count.\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "Later we will see if their is any impact of Response on Netflix Movies."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Duration"
      ],
      "metadata": {
        "id": "RHYO2JQaAHhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "tv_shows = df[df['type'] == 'TV Show']\n",
        "movies = df[df['type'] == 'Movie']\n",
        "\n",
        "# Select the durations for both.\n",
        "duration_tv_shows = tv_shows['duration'].reset_index()\n",
        "duration_movies = movies['duration'].reset_index()\n",
        "\n",
        "# Remove string values from tv shows duration.\n",
        "duration_tv_shows.duration = duration_tv_shows.duration.str.replace(' Season', '') \\\n",
        "                                                       .str.replace(' Seasons', '') \\\n",
        "                                                       .str.replace('s', '')                                                       \n",
        "duration_tv_shows.duration = duration_tv_shows.duration.astype(str).astype(int)\n",
        "\n",
        "# Remove string values from movie duration.\n",
        "duration_movies.duration = duration_movies.duration.str.replace(' min', '')                                                       \n",
        "duration_movies.duration = duration_movies.duration.astype(str).astype(int)"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the above durations.\n",
        "plt.figure(figsize=(8,4), dpi=120)\n",
        "sns.set(style=\"darkgrid\")\n",
        "sns.histplot(data=duration_tv_shows['duration'], color='#db0000')\n",
        "plt.title('Duration of Tv Shows.')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7OOun5kMANHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,4), dpi=120)\n",
        "sns.set(style=\"darkgrid\")\n",
        "sns.histplot(data=duration_movies['duration'], color='#db0000')\n",
        "plt.title('Duration of movies')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9utxBAk4ASNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        "\n",
        "\n",
        "We choose the chart as it represents the count & duration of each part of the data to a whole where the arc size of each slice is directly proportional to the contribution of that part"
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "We see that maximum duration of movie  count is 380 count &  minimum count 9of duration of movie is 20."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "Later we will see if their is any impact of Response on Netflix Movies."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rating:"
      ],
      "metadata": {
        "id": "1goX4vr1AXNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "order =  ['G', 'TV-Y', 'TV-G', 'PG', 'TV-Y7', 'TV-Y7-FV', 'TV-PG', 'PG-13', 'TV-14', 'R', 'NC-17', 'TV-MA']\n",
        "plt.figure(figsize=(15,7))\n",
        "g = sns.countplot(df.rating, hue=df.type, order=order, palette='Set2_r');\n",
        "plt.title(\"Ratings for Movies & TV Shows\")\n",
        "plt.xlabel(\"Rating\")\n",
        "plt.ylabel(\"Total Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finding top 20 movie genres in movies and TV shows\n",
        "genres_shows = shows_df.listed_in.str.split(', ', expand=True).stack().reset_index(level=1, drop=True)\n",
        "genres_movies = movie_df.listed_in.str.split(', ', expand=True).stack().reset_index(level=1, drop=True)\n",
        "\n",
        "\n",
        "fig , axes = plt.subplots(1,2, figsize = (15,8))\n",
        "\n",
        "sns.countplot(y = genres_shows, order=genres_shows.value_counts().index[:20], ax= axes[0])\n",
        "sns.countplot(y = genres_movies, order=genres_movies.value_counts().index[:20], ax= axes[1])\n",
        "\n",
        "axes[0].set_xlabel('count', fontsize = 15, c='b')\n",
        "axes[1].set_xlabel('count', fontsize = 15, c='b')\n",
        "axes[0].set_ylabel('genres', fontsize = 20, c = 'b')\n",
        "axes[0].set_title('Top 20 shows genres', fontsize = 15)\n",
        "axes[1].set_title('Top 20 movie genres', fontsize = 15 )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# plt.figure(figsize=(7,9))\n",
        "# g = sns.countplot(y = genres_shows, order=genres_shows.value_counts().index[:20])\n",
        "\n",
        "# plt.xlabel('Titles')\n",
        "plt.ylabel('Genres')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tPLfJm5QAkXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        "\n",
        "This chart shows tha count of tv shows and movies saperately   of each and every genres."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "we can see that international movies count are 1200 and count of international tv shows are 2400.\n"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "Later we will see if their is any impact of Response on Netflix Movies."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Actors"
      ],
      "metadata": {
        "id": "bvLBAlR6AxV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "tv_shows_df = df[df['type'] == 'TV Show']\n",
        "tv_shows_actors = tv_shows_df[tv_shows_df['cast'] != 'not available']\n",
        "\n",
        "movies_df  = df[df['type']== 'Movie']\n",
        "movie_actors = movies_df[movies_df['cast'] != 'not available']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "top_shows_actors =  tv_shows_actors.cast.str.split(',', expand= True).stack().reset_index(level =1, drop = True)\n",
        "top_movie_actors =  movie_actors.cast.str.split(',', expand= True).stack().reset_index(level =1, drop = True)\n",
        "\n",
        "\n",
        "\n",
        "fig , axes = plt.subplots(1,2, figsize = (15,8))\n",
        "\n",
        "sns.countplot(y = top_shows_actors, order=top_shows_actors.value_counts().index[:15], ax= axes[0], palette ='cividis_r')\n",
        "sns.countplot(y = top_movie_actors, order=top_movie_actors.value_counts().index[:15], ax= axes[1], palette = 'cividis_r')\n",
        "\n",
        "axes[0].set_xlabel('count', fontsize = 15, c='black')\n",
        "axes[1].set_xlabel('count', fontsize = 15, c='black')\n",
        "axes[0].set_ylabel('Actors', fontsize = 20, c = 'black')\n",
        "axes[0].set_title('Top 15 shows actors', fontsize = 15)\n",
        "axes[1].set_title('Top 15 movie actors', fontsize = 15 )\n",
        "\n",
        "plt.ylabel('Actors')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        "\n",
        "\n",
        "\n",
        "This chart shows tha count of tv shows  actors  and count of  tv movies actor  saperately of each and every  chart.\n",
        "\n"
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "we aacn see that the count of tv shows actor are maximum and the count of movies actor  are less.  "
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Most used word in title of content on Netflix"
      ],
      "metadata": {
        "id": "bFCHuMmuA0Tx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the wordcloud\n",
        "from wordcloud import WordCloud,ImageColorGenerator"
      ],
      "metadata": {
        "id": "trXeSPeDA6hM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "text = \" \".join(topic for topic in df.title.astype(str))\n",
        "print (\"There are {} words in the combination of all titles.\".format(len(text)))\n",
        "\n",
        "# Create and generate a word cloud image:\n",
        "wordcloud = WordCloud(background_color=\"black\", width=800, height=400).generate(text)\n",
        "\n",
        "plt.axis(\"off\")\n",
        "plt.rcParams[\"figure.figsize\"] = (14,6)\n",
        "plt.tight_layout(pad=0)\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cast: "
      ],
      "metadata": {
        "id": "YkBRJMhUBEKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "df['cast_name'] = df['cast'].apply(lambda x :  x.split(',')) \n",
        "cast_count = []\n",
        "for i in df['cast_name']: cast_count += i\n",
        "    \n",
        "cast_dict = dict((i, cast_count.count(i)) for i in cast_count)\n",
        "\n",
        "df_cast_count = pd.DataFrame(cast_dict.values(),cast_dict.keys()).reset_index().sort_values(0,ascending=False).rename(\n",
        "    columns = {'index' : 'cast_name', 0 : 'count'}).iloc[1:21]\n",
        "plt.figure(figsize=(15,5))\n",
        "sns.barplot(x='cast_name',y='count',data=df_cast_count,palette=\"Dark2_r\")\n",
        "plt.title(\"Top-20 ACTORS on Netflix\",size='16',fontweight=\"bold\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        "\n",
        "\n",
        "this chart shows the top 20 actors name with the value of count here."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "\n",
        "here we can see that anupam kher has a hinghest count of 38 and arsani haas the less count of 17 which is very less in comaprison with others ."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "there is no negative point of affecting the growth.if there is any we will deal with it later.\n"
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Director:"
      ],
      "metadata": {
        "id": "Ko2agfchBNq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "plt.figure(figsize=(10,5))\n",
        "df[~(df['director']=='Unknown') & (df['type']=='Movie')].director.value_counts().nlargest(10).plot(kind='barh')\n",
        "plt.title('Top 10 movie directors')"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 10 TV show directors\n",
        "plt.figure(figsize=(10,5))\n",
        "df[~(df['director']=='Unknown') & (df['type']=='TV Show')].director.value_counts().nlargest(10).plot(kind='barh')\n",
        "plt.title('Top 10 TV show directors')"
      ],
      "metadata": {
        "id": "A5aen_59BW1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        "\n",
        "1.  TO shows the top 10 tv shows director.\n",
        "2.   values of alll the director.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "here qee cn see thet alastair fotergill has the hinghest count \n"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "Later we will see if their is any impact of Response on Netflix Movies."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Release_year : Actual Releaseyear of the movie / show"
      ],
      "metadata": {
        "id": "OC4L8OxbBaos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "fig, ax = plt.subplots(figsize=(15, 8))\n",
        "sns.countplot(x=\"release_year\", data=df)\n",
        "plt.title(\"Number of movie/show relesed on year\")\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(rotation =90)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        "\n",
        "In this chart shows the top  year top year 2018 with the value of count here relesed year."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "here see can thet 2018 has the hinghest count"
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "there is no negative point of affecting the growth.if there is any we will deal with it later."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Country where the movie / show was produced"
      ],
      "metadata": {
        "id": "a9SGnp0yBjwv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "df[\"country\"].value_counts()[:15].sort_values(ascending=False).plot(kind=\"bar\")\n",
        "plt.title(\"Top 15 Country where the movie / show was produced\")\n",
        "plt.xlabel(\"Country\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        "\n",
        "TO shows the top 10 tv shows country.\n",
        "values of all the count heighest value of united state 2500."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "here qee cn see thet united state has the hinghest count "
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "Later we will see if their is any impact of count on Movies."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# listed_in : Genere"
      ],
      "metadata": {
        "id": "LqGCh3Z5Bq6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "plt.figure(figsize=(10,5))\n",
        "df.listed_in.value_counts().nlargest(10).plot(kind='barh', color= 'crimson')\n",
        "plt.title('Top 10 genres', fontweight = 'bold')\n",
        "#sns.countplot(palette = 'cubehelix')"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        "\n",
        "This chart shows tha count of genres and count of tv movies actor saperately of each and every chart."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "we aacn see that the count of genres 350 are maximum and the count of movies actor are less."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "plt.figure(figsize = (14,12))\n",
        "sns.heatmap(df.corr(), annot = True,  cmap = 'viridis')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        "\n",
        "HO:movies rated for kids and older kids are at least two hours long.\n",
        "\n",
        "H1:movies rated for kids and older kids are not at least two hours long."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies"
      ],
      "metadata": {
        "id": "nYP-xkVDEF05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#making copy of df_clean_frame\n",
        "df_hypothesis=df.copy()\n",
        "#head of df_hypothesis\n",
        "df_hypothesis.head()"
      ],
      "metadata": {
        "id": "ru8bX6jiEKf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filtering movie from Type_of_show column\n",
        "df_hypothesis = df_hypothesis[df_hypothesis[\"type\"] == \"Movie\"]"
      ],
      "metadata": {
        "id": "1raUS8DbEKaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#with respect to each ratings assigning it into group of categories                 \n",
        "ratings_ages = {\n",
        "    'TV-PG': 'Older Kids',\n",
        "    'TV-MA': 'Adults',\n",
        "    'TV-Y7-FV': 'Older Kids',\n",
        "    'TV-Y7': 'Older Kids',\n",
        "    'TV-14': 'Teens',\n",
        "    'R': 'Adults',\n",
        "    'TV-Y': 'Kids',\n",
        "    'NR': 'Adults',\n",
        "    'PG-13': 'Teens',\n",
        "    'TV-G': 'Kids',\n",
        "    'PG': 'Older Kids',\n",
        "    'G': 'Kids',\n",
        "    'UR': 'Adults',\n",
        "    'NC-17': 'Adults'\n",
        "}\n",
        "\n",
        "df_hypothesis['target_ages'] = df_hypothesis['rating'].replace(ratings_ages)\n",
        "#let's see unique target ages \n",
        "df_hypothesis['target_ages'].unique()"
      ],
      "metadata": {
        "id": "NPuoPLaVESx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Another category is target_ages (4 classes).\n",
        "df_hypothesis['target_ages'] = pd.Categorical(df_hypothesis['target_ages'], categories=['Kids', 'Older Kids', 'Teens', 'Adults'])\n",
        "#from duration feature extractin string part and after extracting Changing the object type to numeric\n",
        "df_hypothesis['duration']= df_hypothesis['duration'].str.extract('(\\d+)')\n",
        "df_hypothesis['duration'] = pd.to_numeric(df_hypothesis['duration'])\n",
        "#head of df_\n",
        "df_hypothesis.head(3)"
      ],
      "metadata": {
        "id": "wBHhippXESsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#group_by duration and target_ages                 \n",
        "group_by_= df_hypothesis[['duration','target_ages']].groupby(by='target_ages')\n",
        "#mean of group_by variable\n",
        "group=group_by_.mean().reset_index()\n",
        "group"
      ],
      "metadata": {
        "id": "x2fPLd1eEeXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#In A and B variable grouping values \n",
        "A= group_by_.get_group('Kids')\n",
        "B= group_by_.get_group('Older Kids')\n",
        "#mean and std. calutation for kids and older kids variables\n",
        "M1 = A.mean()\n",
        "S1 = A.std()\n",
        "\n",
        "M2= B.mean()\n",
        "S2 = B.std()\n",
        "\n",
        "print('Mean for movies rated for Kids {} \\n Mean for  movies rated for older kids {}'.format(M1,M2))\n",
        "print('Std for  movies rated for Older Kids {} \\n Std for  movies rated for kids {}'.format(S2,S1))"
      ],
      "metadata": {
        "id": "X1WGZbprEeS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import stats \n",
        "from scipy import stats\n",
        "#length of groups and DOF\n",
        "n1 = len(A)\n",
        "n2= len(B)\n",
        "print(n1,n2)\n",
        "\n",
        "dof = n1+n2-2\n",
        "print('dof',dof)\n",
        "\n",
        "sp_2 = ((n2-1)*S1**2  + (n1-1)*S2**2) / dof\n",
        "print('SP_2 =',sp_2)\n",
        "\n",
        "sp = np.sqrt(sp_2)\n",
        "print('SP',sp)\n",
        "\n",
        "#tvalue\n",
        "t_val = (M1-M2)/(sp * np.sqrt(1/n1 + 1/n2))\n",
        "print('tvalue',t_val[0])"
      ],
      "metadata": {
        "id": "RrYWFkiQEld2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#t-distribution\n",
        "stats.t.ppf(0.025,dof)"
      ],
      "metadata": {
        "id": "2f2AuYinElRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#t-distribution\n",
        "stats.t.ppf(0.975,dof)"
      ],
      "metadata": {
        "id": "m2XVS_G6Er_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "H1:The duration which is more than 90 mins are movies\n",
        "\n",
        "HO:The duration which is more than 90 mins are NOT movies"
      ],
      "metadata": {
        "id": "00dqqRBEE1ge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#making copy of df_clean_frame\n",
        "df_hypothesis=df.copy()\n",
        "#head of df_hypothesis\n",
        "df_hypothesis.head()"
      ],
      "metadata": {
        "id": "dsAEOND5Ey6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_hypothesis['duration']= df_hypothesis['duration'].str.extract('(\\d+)')\n",
        "df_hypothesis['duration'] = pd.to_numeric(df_hypothesis['duration'])\n",
        "#head of df_"
      ],
      "metadata": {
        "id": "SFquuLc_Ey2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_hypothesis['type'] = pd.Categorical(df_hypothesis['type'], categories=['Movie','TV Show'])\n",
        "#from duration feature extractin string part and after extracting Changing the object type to numeric\n",
        "#df_hypothesis['duration']= df_hypothesis['duration'].str.extract('(\\d+)')\n",
        "#df_hypothesis['duration'] = pd.to_numeric(df_hypothesis['duration'])\n",
        "#head of df_\n",
        "df_hypothesis.head(3)"
      ],
      "metadata": {
        "id": "rQ2Ghkv0E_js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#group_by duration and TYPE                 \n",
        "group_by_= df_hypothesis[['duration','type']].groupby(by='type')\n",
        "#mean of group_by variable\n",
        "group=group_by_.mean().reset_index()\n",
        "group\n",
        "     "
      ],
      "metadata": {
        "id": "KamSLntKE_e4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#In A and B variable grouping values \n",
        "A= group_by_.get_group('Movie')\n",
        "B= group_by_.get_group('TV Show')\n",
        "#mean and std\n",
        "M1 = A.mean()\n",
        "S1 = A.std()\n",
        "\n",
        "M2= B.mean()\n",
        "S2 = B.std()\n",
        "\n",
        "print('Mean  {}'.format(M1,M2))\n",
        "print('Std  {}'.format(S2,S1))"
      ],
      "metadata": {
        "id": "Bu5NctL1FA8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import stats \n",
        "from scipy import stats\n",
        "#length of groups and DOF\n",
        "n1 = len(A)\n",
        "n2= len(B)\n",
        "print(n1,n2)\n",
        "\n",
        "dof = n1+n2-2\n",
        "print('dof',dof)\n",
        "\n",
        "sp_2 = ((n2-1)*S1**2  + (n1-1)*S2**2) / dof\n",
        "print('SP_2 =',sp_2)\n",
        "\n",
        "sp = np.sqrt(sp_2)\n",
        "print('SP',sp)\n",
        "\n",
        "#tvalue\n",
        "t_val = (M1-M2)/(sp * np.sqrt(1/n1 + 1/n2))\n",
        "print('tvalue',t_val[0])"
      ],
      "metadata": {
        "id": "o-uT0KUyFHYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#t-distribution\n",
        "stats.t.ppf(0.025,dof)"
      ],
      "metadata": {
        "id": "cglhFe4xFHQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#t-distribution\n",
        "stats.t.ppf(0.975,dof)"
      ],
      "metadata": {
        "id": "RQ_GUtlUFN4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        "\n",
        "We have checked the outliers by plotting the box plot and then replaced the null values of various variables with mean, median,mode and 0 accordingly."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checking for the outliers in countries column\n",
        "df_a = pd.DataFrame(df['country'].value_counts())\n",
        "df_a[df_a['country'] == 1]\n",
        "\n",
        "\n",
        "# basis on this data we cannot find outlier rows in country column"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# detecting outlier detection in shows_df as in this dataframe duration columns contains categorical values i.e seasons\n",
        "\n",
        "# cheking for the percent distribution in duraion column of shows_df\n",
        "\n",
        "\n",
        "shows_df['duration'].value_counts(normalize =True)*100\n",
        "\n",
        "shows_duration = pd.DataFrame(shows_df['duration'].value_counts()).reset_index().rename(columns = {'index' : 'season', 'duration': 'counts'})\n",
        "shows_duration['percent_occupied'] = shows_duration['counts']/len(shows_df)*100\n",
        "shows_duration\n",
        "# based on this result we can assume that there are less than 1 percent shows which are 7 seasons or long hence we can consider these seasons as outliers\n",
        "# however we will be removing content which has more than 10 seasons"
      ],
      "metadata": {
        "id": "nEkm_eBXM-FS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking shape before outlier removal\n",
        "shows_df.shape"
      ],
      "metadata": {
        "id": "YvcYrwa_M-Bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# new shows_df after removing shows having more than 10 seasons\n",
        "list_1 = ['11 Seasons', '12 Seasons', '15 Seasons', '13 Seasons','16 Seasons']\n",
        "\n",
        "shows_df_updated = shows_df[shows_df['duration'] != '11 Seasons'  ]\n",
        "shows_df_updated = shows_df_updated[shows_df_updated['duration'] != '12 Seasons'  ]\n",
        "shows_df_updated = shows_df_updated[shows_df_updated['duration'] != '13 Seasons'  ]\n",
        "shows_df_updated = shows_df_updated[shows_df_updated['duration'] != '14 Seasons'  ]\n",
        "shows_df_updated = shows_df_updated[shows_df_updated['duration'] != '15 Seasons'  ]\n",
        "shows_df_updated = shows_df_updated[shows_df_updated['duration'] != '16 Seasons'  ]\n",
        "shows_df_updated['duration'].value_counts(normalize =True)*100"
      ],
      "metadata": {
        "id": "oaa1LSpNNDhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## checking shape after outlier removal\n",
        "shows_df_updated.shape"
      ],
      "metadata": {
        "id": "ZCzJ61nxNDbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we will be using isllation forest technique to detect outlier in duration column of movies_df\n",
        "\n",
        "# first let see distribution of movies again \n",
        "\n",
        "plt.figure(figsize = (10,7))\n",
        "ax = plt.gca()\n",
        "sns.distplot( x= movie_df['duration'], ax = ax, color = 'y')\n",
        "plt.title('Movie duration distribution')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RZc2J3vGNI8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Isolation forest method to remove outliers from movie duration feature"
      ],
      "metadata": {
        "id": "0RxwttgJN_lO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing isolationForest\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "\n",
        "movie_df1 = movie_df.copy()\n",
        "\n",
        "isolation_forest = IsolationForest(n_estimators = 100, contamination = 0.04, random_state = 42)\n",
        "isolation_forest.fit(movie_df1['duration'].values.reshape(-1,1))\n",
        "movie_df1['anomaly_score'] = isolation_forest.decision_function(movie_df1['duration'].values.reshape(-1,1))\n",
        "movie_df1['-1 if outlier'] = isolation_forest.predict(movie_df1['duration'].values.reshape(-1,1))\n",
        "\n",
        "# printing head of the dataset\n",
        "movie_df1.sort_values('anomaly_score').head()"
      ],
      "metadata": {
        "id": "rcfw_-leNI5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a new dataframe with no outliers\n",
        "movie_df1 = movie_df1[movie_df1['-1 if outlier'] == 1]\n",
        "movie_df_updated = movie_df1.drop(['anomaly_score', '-1 if outlier'], axis = 1)\n",
        "movie_df_updated.head()"
      ],
      "metadata": {
        "id": "huXu-9qOOFBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first let see distribution of movies again \n",
        "\n",
        "plt.figure(figsize = (10,7))\n",
        "\n",
        "fig, axes  = plt.subplots(1,2, figsize = (20,7))\n",
        "ax = plt.gca()\n",
        "\n",
        "\n",
        "sns.distplot( x= movie_df['duration'], color = 'c', bins = 50, ax =axes[0])\n",
        "axes[0].set_title('movies duration distribution before')\n",
        "\n",
        "sns.distplot( x= movie_df_updated['duration'], color = 'r', bins = 50, ax =axes[1])\n",
        "axes[1].set_title('movies duration distribution after')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gtFofhlDOH8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cheking shape of movie_df after outlier removal\n",
        "movie_df_updated.shape"
      ],
      "metadata": {
        "id": "UjbJV093OH2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # creating different columns of genres\n",
        "# genres = updated_dataset['listed_in'].str.split(', ', expand = True)\n",
        "# genres[1].fillna(genres[0], inplace = True)\n",
        "# genres[2].fillna(genres[1], inplace = True)\n",
        "# updated_dataset = pd.concat([updated_dataset, genres], axis = 1).drop('listed_in', axis =1)\n",
        "# updated_dataset.rename(columns = {0 : 'genre1', 1: 'genre2', 2: 'genre3'}, inplace = True)\n",
        "# updated_dataset.head()"
      ],
      "metadata": {
        "id": "UbRB3aQrOOft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Shape of initial dataset\n",
        "initial_df.shape"
      ],
      "metadata": {
        "id": "6KZjVK0iOWzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        "\n",
        "Let's define a code to detect the number of outliers and percentage of outliers present in each of the feature in order to handle them accordingly."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "categorical_features= df.select_dtypes(include='object')"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features"
      ],
      "metadata": {
        "id": "eU74eodsGziF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        "\n",
        "We have used one-hot encoding technique to change our categorical features of object type into int type by creating their dummies so that it becomes compatible to feed it into various ML algorithms in future."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing \n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['description'][0:10]"
      ],
      "metadata": {
        "id": "H3TUs3CtJn7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### . Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "df.head()"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "plt.figure(figsize = (14,12))\n",
        "sns.heatmap(df.corr(), annot = True,  cmap = 'viridis')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA PREPROCESSING"
      ],
      "metadata": {
        "id": "QTWKXYOdNtO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# consolidating dataset and removing unnecessary features\n",
        "updated_dataset = pd.concat([shows_df_updated, movie_df_updated], axis = 0).reset_index().drop('index', axis = 1)\n",
        "cluster_dataset = pd.DataFrame(updated_dataset['listed_in'] + updated_dataset['description'])\n",
        "cluster_dataset.rename(columns = {0 : 'description'}, inplace = True)"
      ],
      "metadata": {
        "id": "wXgvLyFtNxIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cleaning the text\n",
        "def remove_punctuation(text):\n",
        "    '''a function for removing punctuation'''\n",
        "    import string\n",
        "    # replacing the punctuations with no space, \n",
        "    # which in effect deletes the punctuation marks \n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    # return the text stripped of punctuation marks\n",
        "    return text.translate(translator)\n"
      ],
      "metadata": {
        "id": "EiWF3Xc1Pdn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_dataset['description'] = cluster_dataset['description'].apply(remove_punctuation)\n",
        "cluster_dataset"
      ],
      "metadata": {
        "id": "zA7It63jPdkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "id": "7jvYZpknPkiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # create an object of stemming function\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def stem_func(text):    \n",
        "    '''a function which stems each word in the given text'''\n",
        "    text = [lemmatizer.lemmatize(word) for word in text.split()]\n",
        "    return \" \".join(text) "
      ],
      "metadata": {
        "id": "G9I9xylAPkd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_dataset['description'] = cluster_dataset['description'].apply(stem_func)"
      ],
      "metadata": {
        "id": "_cfKPlrgPmTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_cluster =  TfidfVectorizer(stop_words = 'english', max_features = 2000)\n",
        "cluster_tfidf = tf_cluster.fit_transform(cluster_dataset['description'])"
      ],
      "metadata": {
        "id": "iUhTowe8QPsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_tfidf.shape"
      ],
      "metadata": {
        "id": "m-r6QUYZP9BT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert X into array form for clustering\n",
        "X = cluster_tfidf.toarray()\n",
        "X"
      ],
      "metadata": {
        "id": "iJtDxAC8QdiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform a PCA to visualize clusters\n",
        "pca = PCA(n_components = 2)\n",
        "visualize_df =pd.DataFrame(pca.fit_transform(X))\n",
        "visualize_df.head()"
      ],
      "metadata": {
        "id": "dARlFdXPQkfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here.\n",
        "\n",
        "Section 1: In this section we have simply loaded our dataset into google colab and explored the basic information about data.\n",
        "\n",
        "Section 2: In section 2 we have dealt with missing values and imputed the missing values depending on the certain assumption so that we do not miss out important information of the data.\n",
        "\n",
        "Section 3: In this section We have foused on the EDA part where we have performed a detailed EDA on all the possible columns we have drawn a lot of insights even though the data in some columns was not in appropriate format such as cast, listed_in etc.\n",
        "\n",
        "Section 4: in this section we have dealt with outliers where we have used general way remove categorical outliers and then we have used isolation forest to remove numeric outliers and visualise out data before and after the process.\n",
        "\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}